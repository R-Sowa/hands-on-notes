{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a27ba61",
   "metadata": {},
   "source": [
    "## **Fast Gradient Signed Method** による敵対的ノイズ生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a285211",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d04953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# セットアップ\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット準備\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),        # [0, 1] に正規化\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=64, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=1, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_set)}, Test size: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルには単純なCNNを使用\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding = 1), # 28 * 28 -> 28 * 28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                 # 28 * 28 -> 14 * 14\n",
    "            nn.Conv2d(32, 64, 3, padding = 1), # 14 * 14 -> 14 * 14\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                   # 14 * 14 -> 7 * 7\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習 & ベースライン精度の確認\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "epochs = 5 # デモ用に短縮\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# ベースライン精度\n",
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "base_acc = correct / len(test_set)\n",
    "print(f\"Baseline Accuracy: {base_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM関数の定義\n",
    "def fgsm_attack(image: torch.Tensor, epsilon: float, data_grad: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Fast Gradient Sign Method (FGSM) による敵対的な摂動を生成する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: torch.Tensor\n",
    "        元画像。形状(1, 1, 28, 28)を想定\n",
    "    epsilon: float\n",
    "        摂動の強度 0<=epsilon<=1\n",
    "    data_grad: torch.Tensor\n",
    "        損失関数の入力画像に対する勾配\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        摂動を加えた画像 (同形状)\n",
    "    \"\"\"\n",
    "    # 勾配の符号\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # 摂動を加算\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    # 画素値を[0, 1]にクリップ\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化 (単一サンプル)\n",
    "epsilons = [0.05 * i for i in range(7)]\n",
    "examples = []\n",
    "\n",
    "# 1枚ランダムに選ぶ\n",
    "idx = random.randint(0, len(test_set)-1)\n",
    "image, label = test_set[idx]\n",
    "image = image.unsqueeze(0).to(device) # バッチ次元を付与\n",
    "image, label = image.to(device), torch.tensor([label]).to(device)\n",
    "\n",
    "# 勾配計算用にrequires_grad\n",
    "image.requires_grad = True\n",
    "output = model(image)\n",
    "init_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "if init_pred.item() != label.item():\n",
    "    print(\"Model misclassified the original sample, try another idx.\")\n",
    "else:\n",
    "    loss = nn.CrossEntropyLoss()(output, label)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    data_grad = image.grad.data\n",
    "\n",
    "    for eps in epsilons:\n",
    "        perturbed = fgsm_attack(image, eps, data_grad)\n",
    "        out = model(perturbed)\n",
    "        pred = out.max(1, keepdim=True)[1].item()\n",
    "        examples.append((eps, perturbed.squeeze().detach().cpu(), pred))\n",
    "\n",
    "# 描画\n",
    "def imshow(img, title=\"\"):\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(np_img, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, (eps, ex, pred) in enumerate(examples):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    imshow(ex, title=f\"ε={eps}\\nPred={pred}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b00611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全テスト画像にFGSMを適用して精度低下をプロット\n",
    "def test_fgsm(\n",
    "        model: nn.Module,\n",
    "        device: torch.device, \n",
    "        loader: torch.utils.data.DataLoader, \n",
    "        epsilon: float,\n",
    ")-> float:\n",
    "    \"\"\"\n",
    "    指定したepsilonでFGSM攻撃を施しテストデータ全体の精度を計算する\n",
    "\n",
    "    Parameters:\n",
    "    model: nn.Module\n",
    "        評価対象の学習済みモデル\n",
    "    device: torch.device\n",
    "        実行デバイス (CPU / CUDA)\n",
    "    loader: torch.DataLoader\n",
    "        ミニバッチ単位で反復可能なテストデータローダー\n",
    "    epsilon: float\n",
    "        FGSMの摂動強度\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        正解率\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data.requires_grad = True\n",
    "\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        # 既に誤分類しているサンプルはスキップ\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        perturbed = fgsm_attack(data, epsilon, data_grad)\n",
    "        out = model(perturbed)\n",
    "        final_pred = out.max(1, keepdim=True)[1]\n",
    "\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "\n",
    "    return correct / float(len(loader))\n",
    "\n",
    "accuracies = []\n",
    "for eps in epsilons:\n",
    "    acc = test_fgsm(model, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    print(f\"Epsilon: {eps:.2f}  Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# プロット\n",
    "plt.figure()\n",
    "plt.plot(epsilons, accuracies, marker=\"o\")\n",
    "plt.xlabel(\"Epsilon (ε)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"FGSM: Epsilon vs Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
